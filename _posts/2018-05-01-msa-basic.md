## Monolithic Architecture
모노리틱 아키텍쳐란, 기존의 전통적인 웹 시스템 개발 스타일로 하나의 어플리케이션(war)에 모든 기능이 다 들어가 있는 형태를 의미한다. 
<br/><br/>
아래 이미지처럼, 모든 모듈에 대해 UX로직부터 비지니스 레이어까지 통합 되어 있는 구조
<br/>
<br/>
![monolithic-image](/Users/carrey/Desktop/git-page/jaehun2841.github.io/img/2018-05-01-msa-basic/monolithic.png)
<br/>
<br/>

<p>모노리틱(Monolithic)은 무슨 뜻 일까? 구글 번역기로 검색을 해보면..</p>

![search-image](/Users/carrey/Desktop/git-page/jaehun2841.github.io/img/2018-05-01-msa-basic/search.png)
<br/><br/>
하나로 뭉쳐져 있다라는 느낌이 강하게 오는 단어 인듯 합니다.
<br/><br/>


- 장점
  - 하나의 어플리케이션으로 관리되기 때문에 배포/운영이 간단하다<br/>
    (작은 사이트에서는 오히려 더 편한 방법)
  - 트랜잭션 관리가 쉽다 (@Transaction으로 한번에 묶어 처리가 가능)
  - 테스트 케이스 작성이 간편하며, 테스트가 편하다

- 단점
  - 서비스가 늘어날 수록 어플리케이션의 덩치(?)가 커진다. 
  - 개발자가 전체 서비스에 대한 구조를 이해하는데 오래 걸린다.
  - 서비스가 늘어날 수록 빌드시간, 배포시간이 오래 걸린다.
  - 일부분에 대한 수정 후 배포 시, 전체 서비스를 배포해야 한다.
  - 부분적인 장애가 전체 서비스 장애로 번질 수 있다. <br/>
    (한 군데로 트래픽이 몰리는 경우 전체 시스템에 영향을 줄 수 있다.)
  - 한 두사람의 실수가 전체 시스템 빌드에 실패 할 수 있다.
  - 선택적 Scale out이 불가능하다. <br/>
    (좌석 선점, 결제 기능이 있을 때 좌석 선점 기능에 대한 scale out이 요구되지만 결국 전체 서비스에 대한 scale out이 필요하다)
  - 개발 언어에 종속적이다. <br/>
    (개발 기반이 java + Spring이라면 다른기능 또한 java + Spring기반으로 개발 해야한다.)

<br/><br/>
## MSA (Micro Service Architecture) - Don`t put all your eggs in one basket

 Spring MSA란, Spring Micro Service Architecture라는 의미로 기존의 거대한 EnterPrise Service를 각 모듈 별, 기능 별로 서비스를 세분화 하여 개발하는 방법론입니다.<br/>
대용량 웹서비스가 많아짐에 따라 정의된 아키텍처이며, SOA(Service Oriented Architecture)에 근간을 두고 있습니다. <br/>
SOA는 엔터프라이즈 시스템을 중심으로 고안된 아키텍쳐라면, 마이크로 서비스 아키텍쳐는 SOA 사상에 근간을 두고, 대용량 웹서비스 개발에 맞는 구조로 사상이 경량화 되고, 대규모 개발팀의 조직 구조에 맞도록 변형된 아키텍쳐입니다.

<br/><br/>
![모노리틱 아키텍처](/Users/carrey/Desktop/git-page/jaehun2841.github.io/img/2018-05-01-msa-basic/monolithic-diagram.png) 
<br/><br/>

### 모노리틱(Monolithic) 아키텍처 구조
위 에서 봤듯이 모노리틱(Monolithic) 아키텍처 구조에서는 
* 프레젠테이션 레이어(Front)
* 비지니스 레이어(Service)
* 퍼시스턴트(Persistence) 레이어

<br/>
구성되어 하나의 어플리케이션으로 동작하고 있습니다. <br/>
<br/>
이를 MSA를 이용하여 개발하게 된다면 아래와 같은 구조로 접근해 볼 수 있습니다.
<br/><br/>
![MSA 아키텍처](/Users/carrey/Desktop/git-page/jaehun2841.github.io/img/2018-05-01-msa-basic/msa-diagram.png) 
<br/><br/>

<br/><br/>
![MSA](/Users/carrey/Desktop/git-page/jaehun2841.github.io/img/2018-05-01-msa-basic/ux-msa.png)
<br/><br/>

### 마이크로 서비스 아키텍처(MSA) 구조
가로 방향으로 레이어에 대한 구분으로 시스템을 구분 했다면, MSA에는 모듈, 도메인 단위로 세로 방향으로 시스템을 구분합니다.<br/>
즉 각각의 도메인 별로 프레젠테이션 레이어 + 비지니스 레이어 + 퍼시스턴트 레이어를 가지며, DB또한 인스턴스가 분리되는 구조를 가집니다. <br/>
<br/>
기존의 모노리틱(Monolithic) 구조의 call-by-reference를 이용한 method 호출에서 굳이 오버헤드를 만들어 가며 REST API 형태로 바꿈으로써 얻을 수 있는 장점은 무엇이고, 단점은 무엇일까요?

- 장점
  - 다른 서비스의 의존성 (Dependency)와 관계 없이 배포 가능
  - 경량 어플리케이션 -> 빠른 빌드/배포
  - 선택적 Scale out 가능 (AWS에서는 Auto Scaling이 가능)
  - Poly glot아키텍처 구성 가능 (어디는 Java+Spring, 어디는 Node.js등.. 필요한 곳에 필요한 기술을 사용할 수 있다.)
  - 하나의 서비스가 다른 서비스에 영향을 주지 않는다. (죽은 서비스를 호출 하게 되면 문제가 됩니다.)
  - 낮은 결합도, 높은 응집력
  
- 단점
  - 트랜잭션 처리가 매우 어렵다.
    기존에 Call-by-reference방식으로 메소드만 호출하던 부분을 @Transaction으로만 묶어줬다면,
    이제는 각 서비스 별로 Rollback을 별도 처리 해줘야 합니다.
  - 성능 이슈가 있다. 
    기존 모노리틱(Monolithic) 구조에서는 서비스 간 Dependency, DI를 이용하여 직접 method를 호출 하는 방식에서
    이제는 http프로토콜을 이용한 API 호출방식으로 변경 되었습니다.
    분명 이 과정에서 Network IO에 대한 오버헤드(Overhead)가 발생하므로 모노로틱(Monolothic) 구조보단 상대적으로 느릴 수 밖에 없습니다.
    하지만 하드웨어가 발달 된 현 시점에서, 많은 차이가 나지 않는다고 하면 MSA방식을 채택 하는 것이 더 좋습니다.
  - 관리 포인트가 늘어난다.
    모노로틱(Monolithic) 구조에서는 n-tier에 대한 서버 인스턴스만 관리하면 되어, 관리 서버의 수가 적었습니다.<br/>
    하지만 MSA 구조에서는 서비스 수 x 서버 인스턴스 + a로 늘어 나게 되며, 배포, 모니터링 환경에 대한 관리 포인트가 많아지게 됩니다.
    이 과정에서 발생하는 비용도 많아지게 됩니다.
  - 각 서비스 간 통신 시, Model Spec에 의존하게 된다.
    각 서비스 간 API 통신 시, VO, DTO등이 생성되게 될 텐데, 결국은 JSON형태로 데이터를 주고 받아 Serializing/Deserializing이 이루어지는 형태
    Model 데이터가 변경 될 경우 타 서비스에 장애를 초래 하거나 정상적으로 서비스가 동작 하지 않을 수 있다.


### MSA 구조의 경계는 어떻게 구분하는게 좋을까?
* 자율적인 기능 
* SRP (Single Response Principle) - 단일 책임의 원칙 
* 배포 단위의 크기 
* 서브도메인 
* Polyglot 아키텍처 
* 선택적 확장 (Scale out)
* 작고 애자일한 팀 
* 트랜잭션


## API Gateway

API Gateway란, 간단하게 모든 API 서버 앞단에서 End-Point를 단일/통합 하는 서버입니다. <br/>
<br/>
추가로 아래 기능을 제공하고 있습니다. <br/> 
1. 인증 (Certification) <br/>
   * 인증의 대표적인 예로 API Token 발행이 있습니다. <br/>
   * Application에 로그인 하는 경우, 여러 서비스에 대한 SSO처리 없이 Session을 유지할 수 있습니다.<br/><br/>
   ![auth](/Users/carrey/Desktop/git-page/jaehun2841.github.io/img/2018-05-01-msa-basic/token.png)<br/>
2. 권한 (Authority) <br/><br/>
3. 라우팅 (Routing) <br/>
   * API Gateway에서는 각 API서버에 대한 라우팅 및 로드밸런싱을 제공 합니다. <br/><br/>
   ![auth](/Users/carrey/Desktop/git-page/jaehun2841.github.io/img/2018-05-01-msa-basic/noapigateway.png)<br/><br/>
   API Gateway가 없는 형태 <br/><br/>
   ![auth](/Users/carrey/Desktop/git-page/jaehun2841.github.io/img/2018-05-01-msa-basic/apigateway.png)<br/><br/>
   API Gateway가 있는 형태 <br/><br/>
   
   * AWS와 같은 클라우드 환경을 사용할 경우 Auto scaling과 같은 기능을 사용하게 되는데, 이 경우 Spring Cloud Eureka와 같은 라이브러리를 통해 자동으로 서버에 대한 정보를 등록하여, <br/>
   API서버 별로 로드 밸런싱을 통해 트래픽 분산이 가능합니다.<br/>
   * 단순하게 라운드 로빈으로 분산이 가능하며, 서버의 하드웨어 조건에 따라 가중치를 설정하여 트래픽을 분산하는 것도 가능합니다.
   * 메세지 헤더 기반 라우팅이 가능합니다. en_us, ko_kr등의 Country_code에 따라 해외에 있는 서버로의 요청도 분산 할 수 있습니다.<br/><br/>
   ![country](/Users/carrey/Desktop/git-page/jaehun2841.github.io/img/2018-05-01-msa-basic/country.png)
   
4. 모니터링 (Monitoring)
   * AWS API Gateway와 같은 일부 API Gateway에서는 API Gateway에 대한 모니터링을 제공합니다.
   * 아래 이미지는 오픈 소스 API Gateway인 Kong에서 제공하는 모니터링입니다.<br/><br/>

   ![maxresdefault](/Users/carrey/Desktop/git-page/jaehun2841.github.io/img/2018-05-01-msa-basic/maxresdefault.jpg)
   
5. 공통 로직처리
   * API Gateway 특성상, 각 API 서버들의 앞 단에 위치하기 때문에 각 서비스에서 필요한 Session정보나, 전처리 정보등을 공통으로 처리 할 수 있습니다.
   * 모든 API가 거쳐가는 곳이기 때문에 동일한 포맷으로 로그를 처리하기 좋습니다.
     이러한 로그는 차후 장애분석이나, 트래픽 분석등에 중요한 지표로 사용 될 수 있습니다.<br/><br/>
   ![token](/Users/carrey/Desktop/git-page/jaehun2841.github.io/img/2018-05-01-msa-basic/a8.png)
   

* 장점
  * 각 API서버에 대한 Dependency를 최소화 할 수 있음
  * 모든 API서버는 API Gateway에만 Dependency가 적용
  * 각 서비스에서는 API Gateway를 통해 상호 간 통신 (서버에 대한 IP/Port정보를 일일이 확인하지 않아도 됨)
  * Swagger와 같은 라이브러리를 이용하여 API Doc 자동화 관리 가능
  * Eureka와 같은 라이브러리를 이용하면 ServerID로 관리되어 관리가 쉬움 (대신 비용이 많이 듬, 작은 그룹의 API서버는 그냥 라우팅 관리를 해도 된다.)

* 단점
  * 모든 API Call이 API Gateway로부터 시작되기 때문에 API Gateway에 대한 부하가 집중 됨
    (API Gateway를 잘 분리하여 운영하여야 함.)

<br/><br/>


## Circuit Breaker

Circuit Breaker란, 직역하면 누전차단기라는 뜻을 가지고 있습니다. <br/>
전류의 양이 한 순간 급격하게 흘러들어오면 전기를 차단하여.. 집에 불나는 것을 막아줍니다. <br/>
(집에 불이 나서 난리가 나느니... 전기 한번 끊기고 두꺼비집 다시 올려주는 게 낫습니다.) <br/>
<br/>

Circuit Breaker란 많은 내부 API를 호출 해야하는 환경에서, 특정 API로 트래픽이 몰리거나, 서버가 다운되어
장애가 발생 한 경우 시스템의 장애전파를 막는 역할을 수행 합니다.
<br/><br/>
위의 예제로 다시 한번 설명을 해보자면..<br/>
전류의 양이 한순간에 급격하게 흘러들어오면 (특정 트래픽이 한군데로 겁나게 몰리면...)<br/>
다른 말로 일정량 이상의 전류가 흘러들어오면 (특정 API서버에 대한 fail이 특정 횟수 이상 발생하면..)<br/>
누전 차단기(Circuit Breaker)를 내려 전류를 차단합니다 (특정 API에 대한 연결을 차단하고, client에게 에러 메세지를 보여줍니다.)<br/>
로 직역 해 볼 수 있습니다.<br/>
<br/>
<br/>
![장애 상황](/Users/carrey/Desktop/git-page/jaehun2841.github.io/img/2018-05-01-msa-basic/circuit-error.png)
<br/>
<br/>
위의 이미지는 한 API서버에 대한 장애 상황을 나타낸 것입니다.<br/>
API Gateway에서는 한정된 Thread로 외부 API호출을 수행하게 됩니다.<br/>
만약, Circuit Breaker가 없다면 어떤 상황이 벌어질까요?<br/>
API 호출에 할당된 Thread는 API 호출을 수행해야 하기 때문에 Thread pool에 반납되지 못하고 호출이 끝날 때 까지 자원을 선점하게 됩니다.<br/>
이러한 Thread pool 자원이 모두 선점되게 되면 다음 API호출은 수행해줄 Thread를 하염없이 기다리게 되고, 이는 종속 관계의 서비스에 대한 장애로 전파 될 수 있습니다.<br/>

<br/><br/>
![Circuit Breaker1](/Users/carrey/Desktop/git-page/jaehun2841.github.io/img/2018-05-01-msa-basic/no-error-circuit.png)
<br/><br/>

이런 문제를 해결하기 위해 Circuit Breaker 패턴을 사용합니다.<br/>
위의 이미지처럼 Service B에 대한 Dependency를 가지는 Service A에 대해 Service B가 문제 없이 동작한다면,<br/>
위의 이미지대로 각 API서버에 문제가 없다면 Circuit Breaker에 대한 제어는 트래픽을 문제없이 bypass하게 됩니다.
<br/><br/>
![Circuit Breaker2](/Users/carrey/Desktop/git-page/jaehun2841.github.io/img/2018-05-01-msa-basic/circuit-breaker.png)
<br/><br/>
하지만, Service B에서 Slow Query등 시간이 지연되어, timeout이나 장애가 발생하는 경우 <br/>
Circuit Breaker는 미리 지정된 fail횟수를 카운트하여 미리 저정된 횟수 만큼 fail에 발생하면 Service B에 대한 API호출을 막아버립니다.<br/>
이 때 Circuit Breaker에 fallBack 로직을 수행하여 Service A에게 에러메세지를 전달해 주거나, 일시적으로 캐싱된 데이터를 전달하는 등, <br/>
Default 결과 값을 지정하여 전달해 줍니다.<br/>
이런 식으로 Circuit을 닫아 줄 시간을 지정하고 이 시간 동안에는 장애 전파가 되지 않도록 장애 서비스 호출을 하지 않게 됩니다.<br/>
그리고 지정한 시간이 지나면 다시 Circuit을 열고, 절반은 Circuit Breaker fallback로직을 실행하고, 절반은 Service B를 호출 하게 합니다.<br/>
이런 식으로 장애가 해결 되었는지를 판단한 다음에 Circuit을 열어 Service B를 다시 정상적으로 서비스 하도록 합니다.<br/>

<br/><br/>
![Circuit Breaker flow](/Users/carrey/Desktop/git-page/jaehun2841.github.io/img/2018-05-01-msa-basic/circuit-breaker-flow.png)
<br/><br/>
<br/>
### 예제 코드

~~~java
 //2분 내로 5번이 넘는 오류가 발생하면 10분동안 Circuit을 닫고 breaker.checkState()에서 false 리턴
 EventCountCircuitBreaker breaker = new EventCountCircuitBreaker(5, 2, TimeUnit.MINUTE, 5, 10, TimeUnit.MINUTE);
 ...
 public void handleRequest(Request request) {
     
     // Circuit Breaker의 상태 체크 true면 서비스 호출 로직을 실행
     if (breaker.checkState()) {
         try {
             service.doSomething();
         } catch (ServiceException ex) {
             breaker.incrementAndCheckState();
         }
     } else {
         // return an error code, use an alternative service, etc.
         // 에러인 경우, 캐싱된 데이터를 실행하거나 에러메세지 표현
     }
 }
~~~

<br/><br/>
~~~Java

//1분에 1000건 이상의 Request가 오는 경우 Circuit을 닫는다.
//1분마다 체크하여 800건 이하로 Request가 내려가면 다시 Circuit을 열어준다.
 EventCountCircuitBreaker breaker = new EventCountCircuitBreaker(1000, 1, TimeUnit.MINUTE, 800);
 ...
 public void handleRequest(Request request) {
     if (breaker.incrementAndCheckState()) {
         // actually handle this request
     } else {
         // do something else, e.g. send an error code
     }
 }
~~~

<br/><br/>
## Spring Cloud Netflix
전 세계에서 MSA를 가장 잘 하고 있는 기업은? 하면 Netflix라고 말할 수 있을 정도라고 한다. <br/>
마틴 파울러라는 아저씨가 제시한 MSA모델을 가장 잘 수행하고 구현하고 운영하고 있다고 한다. (뭔지는 모름) <br/>
그런 Netflix라는 회사에서 다른 개발자들도 MSA를 쉽게쉽게 구현하라고 여러가지 라이브러리들을 만들어서 배포하였다고 한다. <br/>
MSA를 위한 오픈소스는 몇가지 있지만, Spring Cloud Netflix는 Java기반으로 만들어져 있고, <br/>
Spring Project에 붙이기 쉽다는 장점이 있다. 또, 모니터링을 위한 UI를 제공해주니 다른 오픈소스 보다는 좋다고 생각이 들고, <br/>
굳이 안쓸 이유가 없다고 생각한다.<br/>
<br/>
아래 라이브러리들은 Spring Cloud Netflix에서 MSA기반의 아키텍처를 구현하기 위한 개념들을 구현 한 라이브러리다.
* Spring Cloud Zuul : API Gateway 구현 시, 로드밸런싱 역할을 해준다. 
* Spring Cloud Hystrix : Circuit Breaker를 구현, 에러를 핸들링 할 수 있도록 인터페이스를 제공
* Spring Cloud Eureka : API 서버에 대한 목록을 가지고 있고, ServiceId를 바탕으로 API서버를 관리하고, 코드내에서 사용하게 해준다. (일종의 DNS역할)
* Spring Cloud Feign : Feign Client라는 개념을 사용하여  API 통신을 추상화 하여 사용한다.
* Spring Cloud Slueth + Zipkin : MSA환경에서 서비스에 대한 Tracing 정보를 제공한다.

### Spring Cloud Zuul
> Spring Cloud에서 말하는 Zuul이란 <br/>
Zuul is the front door for all requests from devices and web sites to the backend of <br/>
the Netflix streaming application. As an edge service application, Zuul is built to enable <br/> 
dynamic routing, monitoring, resiliency and security. It also has the ability to route requests <br/> 
to multiple Amazon Auto Scaling Groups as appropriate.Zuul is the front <br/>
<br/>
한 마디로 Netflix에서 사용하는 API Gateway이며, 동적 라우팅, 모니터링, 탄력성(?), 보안을 제공한다고 한다.

1. Netflix에서는 이러한 이유로 Zuul을 사용한다.
클라이언트 요청은 많은 트래픽과 다양한 형태(예상하지 못한 형태)의 요청으로 경고없이 운영에 이슈를 발생시킨다. 이러한 상황에 신속히 대응할 수 있는 시스템 zuul을 개발하였다. zuul은 이런한 문제를 신속하고, 동적으로 해결하기 위해서 groovy 언어로 작성된 다양한 형태의 Filter를 실행한다. Filter에 기능을 정의하고, 이슈사항에 발생시 적절한 filter을 추가함으로써 이슈사항을 대비할 수 있다.

2. Zuul에서 제공하는 기능
- Authentication and Security
 - 클라이언트 요청시, 각 리소스에 대한 인증 요구 사항을 식별하고 이를 만족시키지 않는 요청은 거부
- Insights and Monitoring
 - 의미있는 데이터 및 통계 제공
- Dynamic Routing
 - 필요에 따라 요청을 다른 클러스터로 동적으로 라우팅
- Stress Testing
 - 성능 측정을 위해 점차적으로 클러스터 트래픽을 증가
- Load Shedding
 - 각 유형의 요청에 대해 용량을 할당하고, 초과하는 요청은 제한
- Static Response handling
 - 클러스터에서 오는 응답을 대신하여 API GATEWAY에서 응답 처리

 ![Zuul](/Users/carrey/Desktop/git-page/jaehun2841.github.io/img/2018-05-01-msa-basic/Zuul-Core-Architecture.png)

(우아한 형제들 블로그 참고)
- Filter File Manager에서는 일정 주기(정해진 시간) 마다 정해진 directory에서 groovy로 정의된 filter 파일을 가져온다.
- avax.servlet.http.HttpServlet을 상속받아서 ZuulServlet을 제정의 하였고, request 요청이 들어 올때마다 아래와 같이 preRoute(), route(), postRoute()에서 ZuulFilter Runner를 실행한다.
- ZuulFilter Runner는 Filter에 정의된 기능을 실행한다.
- 기본적으로 Filter은 다른 Filter들과 직접적으로 통신할 수 없다. 그래서 각각의 요청별로 RequestContext를 공유(마치 thread local같이)하여 통신 할 수 있다.
<br/>

3. Zuul Filter LifeCycle

![Zuul-lifecycle](/Users/carrey/Desktop/git-page/jaehun2841.github.io/img/2018-05-01-msa-basic/Request-Lifecycle.png)

Zuul Filter는 크게 4가지 Filter로 나누어 진다.

* PRE Filter - 라우팅전에 실행되며 필터이다. 주로 logging, 인증등이 pre Filter에서 이루어 진다.
* ROUTING Filter - 요청에 대한 라우팅을 다루는 필터이다. Apache httpclient를 사용하여 정해진 Url로 보낼수 있고, Neflix Ribbon을 사용하여 동적으로 라우팅 할 수도 있다.
* POST Filter - 라우팅 후에 실행되는 필터이다. response에 HTTP header를 추가하거나, response에 대한 응답속도, Status Code, 등 응답에 대한 statistics and metrics을 수집한다.
* ERROR Filter - 에러 발생시 실행되는 필터이다. (Hystrix를 연동한다면 Fallback 로직을 연결)

#### 배민 Zuul Route 사용 예제
~~~yaml
zuul:
  routes:
    baeminApiService:
      path: info/notice/**
      url: http://baeminservice-new-api.com/v1/notice
    baeminLegacyApiService:
      path: /**
      url: http://baeminservice-legacy-api.com
~~~

### Spring Cloud Hystrix

#### Hystrix란?
> Hystrix is a latency and fault tolerance library designed to isolate points of access to remote systems, services and 3rd party libraries, stop cascading failure and enable resilience in complex distributed systems where failure is inevitable.

Netflix에서 개발해 사용 중인 오픈소스로, 원격 시스템이나 서비스를 호출하는 구간을 격리해 관리하고 모니티렁해주는 라이브러리이다.
Netflix에서 개발한 Circuit Breaker라이브러리로 각 서비스 호출 간 Circuit Breaker를 삽입하여 fallback 로직에 대한 인터페이스를 제공한다.

#### 예제 코드

HystrixCommand 상속 방식
~~~Java
public class HystrixTestCommand extends HystrixCommand<String> {
 
    private String world;
 
    public HystrixTestCommand(String world) {
 
        super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey("test2")).andCommandKey(HystrixCommandKey.Factory.asKey("test2-1"))
                .andCommandPropertiesDefaults(HystrixCommandProperties.Setter()));
        this.world = world;
    }
 
    @Override
    protected String run() throws Exception {
 
        return "Hello " + world;
    }
 
    @Override
    protected String getFallback() {
 
        return null;
    }
}
~~~

@HystrixCommand 어노테이션 사용방식
~~~Java
@Service
public class HystrixTestService {
 
    @HystrixCommand(groupKey = "test1", commandKey = "test1-1",
            threadPoolProperties = {@HystrixProperty(name = "coreSize", value ="10"), @HystrixProperty(name="maxQueueSize", value="5")})
    public String testService() {
 
        return "test completed";
    }
}
~~~

#### Hystrix Monitoring 도구 제공
![Hystrix Monitoring](/Users/carrey/Desktop/git-page/jaehun2841.github.io/img/2018-05-01-msa-basic/hystrix-dashboard-example.png)

### Spring Cloud Ribbon (Client Side Load Balancer)

Client Side Load Balencer란? <br/>
이에 대조되는 개념인 Server side Load balancer를 먼저 살펴 보면..<br/>
트래픽 분산 처리를 하기 위해 L4, L7스위치 같은 하드웨어를 통한 로드밸런싱을 지원핟거나, <br/>
HAProxy같은 오픈소스 소프트웨어를 통해 분산을 처리 하였다.<br/>

어쨌든 분산 처리를 해주는 역할을 해주지만, 가장 맨 앞단에서는 모든 요청에 대한 트래픽을 수용하는 모양새가 된다.<br/>
![server-side-lb](/Users/carrey/Desktop/git-page/jaehun2841.github.io/img/2018-05-01-msa-basic/switch.png)

이와 같은 문제를 완화하기 위해 생긴 개념이 Client side load balancer이다.
서버에서 로드 밸런싱을 하는게 아니고 서버 어플리케이션 자체에서 서버그룹을 가지고 로드밸런싱을 하는 것을 의미한다.
![client-side-lb](/Users/carrey/Desktop/git-page/jaehun2841.github.io/img/2018-05-01-msa-basic/client-load.png)

Spring Cloud Ribbon라이브러리에서는 Client side load balancing을 할 수 있는 기능을 제공한다.

#### 예제 

![ribbon-application.yml](/Users/carrey/Desktop/git-page/jaehun2841.github.io/img/2018-05-01-msa-basic/ribbon-setting.png)
<br/>
서버 그룹에 대한 정보를 지정하고, Health Check 시간을 지정하여 다운 된 서버로의 요청을 차단 할 수 있다.

![ribbon-exam](/Users/carrey/Desktop/git-page/jaehun2841.github.io/img/2018-05-01-msa-basic/Ribbon-client-exam.png)
<br/>
@RibbonClient 어노테이션을 통해 서버 군을 지정 할 수 있으며,
위에서 지정한 서버군 이름 (cslb-server라는 도메인을 통해 지정한 서버군에 대한 로드밸런싱을 할 수 있다.)

![ribbon-result](/Users/carrey/Desktop/git-page/jaehun2841.github.io/img/2018-05-01-msa-basic/ribbon-result.png)
<br/>
처리 결과 별도의 Server side load balancer가 없어도 어플리케이션 단에서 로드밸런싱이 가능하다.



### Spring Cloud Eureka

Service Discovery 패턴

* MSA와 같은 분산 서비스 환경에서는 서비스 간의 원격 호출로 구성이 된다.
  원격 호출은 주로 IP주소와 port를 이용하여 호출하게 되는데, 서비스가 많아지고, 사용량이 많아져 Auto Scaling 같은 기능을 사용하게 되면 더더욱 관리해야 할 서버가 많아진다.
  동적으로 변하는 IP주소를 관리 하기 어렵기 때문에 Service Discovery패턴의 개념이 생성 되었다.

* 서비스를 호출 할 때 IP주소와 port를 알아 낼 수 있는 기능이 필요 한데, 

  이를 Service Discovery패턴이라 한다.



Service Registry

* 서비스에 대한 IP주소와 Port를 알아 내기 위해 서비스를 등록해주는 과정이 필요하다.
* 가장 쉬운 방법은 DNS레코드에 하나의 도메인 주소(www.xxx.co.kr)에 여러 IP주소를 등록하는 방법이지만,
  삽입, 갱신 시간이 오래 걸리므로 좋은 방법은 아니다.
* Spring Cloud Eureka를 사용하면 Spring 환경에서 Service Registry, Discovery기능을 쉽게 사용할 수 있다.

![service-registry](/Users/carrey/Desktop/git-page/jaehun2841.github.io/img/2018-05-01-msa-basic/Service-Registry.png)



Eureka Server

* 별도의 Eureka Server Application가 필요
* Spring boot Application에서 **@EnableEurekaServer** 어노테이션으로 간단하게 설정이 가능



Maven 예제

~~~xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<groupId>com.example</groupId>
	<artifactId>eureka-service</artifactId>
	<version>0.0.1-SNAPSHOT</version>
	<packaging>jar</packaging>

	<parent>
		<groupId>org.springframework.boot</groupId>
		<artifactId>spring-boot-starter-parent</artifactId>
		<version>2.0.2.RELEASE</version>
		<relativePath/> <!-- lookup parent from repository -->
	</parent>

	<properties>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
		<java.version>1.8</java.version>
	</properties>

	<dependencies>
		<dependency>
			<groupId>org.springframework.cloud</groupId>
			<artifactId>spring-cloud-starter-netflix-eureka-server</artifactId>
		</dependency>

		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-test</artifactId>
			<scope>test</scope>
		</dependency>
	</dependencies>

	<dependencyManagement>
		<dependencies>
			<dependency>
				<groupId>org.springframework.cloud</groupId>
				<artifactId>spring-cloud-dependencies</artifactId>
				<version>Finchley.RC1</version>
				<type>pom</type>
				<scope>import</scope>
			</dependency>
		</dependencies>
	</dependencyManagement>

	<build>
		<plugins>
			<plugin>
				<groupId>org.springframework.boot</groupId>
				<artifactId>spring-boot-maven-plugin</artifactId>
			</plugin>
		</plugins>
	</build>

	<repositories>
	    <repository>
	        <id>spring-milestones</id>
	        <name>Spring Milestones</name>
	        <url>https://repo.spring.io/libs-milestone</url>
	        <snapshots>
	            <enabled>false</enabled>
	        </snapshots>
	    </repository>
	</repositories>

</project>

~~~



Spring Boot Application 예제

```Java
@EnableEurekaServer //Eureka 서버로 동작
@SpringBootApplication
public class EurekaServiceApplication {

    public static void main(String[] args) {
        SpringApplication.run(EurekaServiceApplication.class, args);
    }
}
```



Eureka Server properties

```yaml

spring:
    application:
        name: eureka-server
server:
    port: 8761

Eureka :
  instance: //Eureka 서버에 등록 될 때 사용하는 옵션
    hostname: localhost 
  client: // Eureka 서버를 찾을 때 사용하는 옵션
    fetch-registry: false //자신이 Eureka 서버이기 때문에 상태를 갱신할 필요 없음
    register-with-eureka: false //자신이 Eureka 서버이기 때문에 클라이언트로 등록하지 않음
      
```



Eureka Client

* 각 API Server에서 Eureka Client를 이용하여 자기자신의 IP주소와 Port정보를 등록
* Eureka Client에서 Eureka Server의 IP정보 등록 하는 구조
* API서버의 IP주소가 유동적으로 변경되거나, 추가되어도 유연하게 활용이 가능함
* @EurekaClient



Maven 예제

~~~Xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<groupId>com.example</groupId>
	<artifactId>eureka-client</artifactId>
	<version>0.0.1-SNAPSHOT</version>
	<packaging>jar</packaging>

	<parent>
		<groupId>org.springframework.boot</groupId>
		<artifactId>spring-boot-starter-parent</artifactId>
		<version>2.0.2.RELEASE</version>
		<relativePath/> <!-- lookup parent from repository -->
	</parent>

	<properties>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
		<java.version>1.8</java.version>
	</properties>

	<dependencies>
		<dependency>
			<groupId>org.springframework.cloud</groupId>
			<artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>
		</dependency>

		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-test</artifactId>
			<scope>test</scope>
		</dependency>
		<dependency>
			<groupId>org.springframework.cloud</groupId>
			<artifactId>spring-cloud-starter-netflix-eureka-server</artifactId>
			<scope>test</scope>
		</dependency>
	</dependencies>

	<dependencyManagement>
		<dependencies>
			<dependency>
				<groupId>org.springframework.cloud</groupId>
				<artifactId>spring-cloud-dependencies</artifactId>
				<version>Finchley.RC1</version>
				<type>pom</type>
				<scope>import</scope>
			</dependency>
		</dependencies>
	</dependencyManagement>

	<build>
		<plugins>
			<plugin>
				<groupId>org.springframework.boot</groupId>
				<artifactId>spring-boot-maven-plugin</artifactId>
			</plugin>
		</plugins>
	</build>

	<repositories>
	    <repository>
	        <id>spring-milestones</id>
	        <name>Spring Milestones</name>
	        <url>https://repo.spring.io/libs-milestone</url>
	        <snapshots>
	            <enabled>false</enabled>
	        </snapshots>
	    </repository>
	</repositories>

</project>
~~~



Spring Boot Application 예제

~~~Java
@EnableDiscoveryClient //Eureka서버에서 Client를 찾을 수 있도록 설정
@SpringBootApplication
public class EurekaClientApplication {

    public static void main(String[] args) {
        SpringApplication.run(EurekaClientApplication.class, args);
    }
}

@RestController
class ServiceInstanceRestController {

    @Autowired
    private DiscoveryClient discoveryClient;

    @RequestMapping("/service-instances/{applicationName}")
    public List<ServiceInstance> serviceInstancesByApplicationName(
            @PathVariable String applicationName) {
        return this.discoveryClient.getInstances(applicationName);
    }
}
~~~



Eureka Client properties

~~~yaml
spring:  
  application:
    name: spring-cloud-eureka-client //Eureka 서버에 등록 될 서비스 명

server:  
  port: 8081 // 서비스 Port

eureka:  
  client:
    registerWithEureka: true //Eureka 서버에 등록 해야됨
    fetchRegistry: true // Eureka 서버에서 갱신 되야함 (연결 끊어지는 경우)
    useDnsForFetchingServiceUrls: false 
    eurekaServerDNSName: localhost
    eurekaServerPort: 8761
    eurekaServerURLContext: eureka
~~~



**@EnableDiscoveryClient** vs **@EnableEurekaClient**

- 둘 다 Eureka서버에 Service Registration 하는 역할
- @EnableDiscoveryClient는 spring-cloud-commons의 라이브러리
  - 다른 Service Discovery 라이브러리(?)에서도 사용할 수 있다고 한다.
- @EnableEurekaClient는 spring-cloud-netflix의 라이브러리
  - 오로지 Eureka Service Discovery를 위해서만 사용한다고 한다.
  - Eureka Client정의 시에는 아무래도 @EnableEurekaClient를 쓰는게 더 좋아 보인다.

Stack overflow 참조 
https://stackoverflow.com/questions/31976236/whats-the-difference-between-enableeurekaclient-and-enablediscoveryclient



### Spring Cloud Feign







### Spring Cloud Slueth + Zipkin



분산 트랜잭션이란, MSA환경에서 여러 하나의 로직이 여러 서비스에 걸쳐 수행되는 것을 의미한다.

MSA환경에서는 하나의 http호출이 여러 서비스를 호출해 가며 로직을 수행하기 때문에 어느 서비스에서 병목현상이 생기는지 파악하기가 어렵다.



아래 예시에서는 사용자가 서비스 A를 호출하지만 서비스 A에서 다른 서비스들을 추가적으로 호출한다.

![](/Users/carrey/Desktop/git-page/jaehun2841.github.io/img/2018-05-01-msa-basic/분산트랜잭션.png)



기존의 모니터링 시스템으로는 한계가 있기 때문에, 우리는 이러한 MSA환경에서 서비스 별로 추적하고 로깅할 수 있는 시스템이 필요하다.



### 작동원리

![](/Users/carrey/Desktop/git-page/jaehun2841.github.io/img/2018-05-01-msa-basic/분산트랜잭션 추적원리.png)

MSA환경에서는 Trace와 Span이라는 개념을 통해 로그를 수집하고 실행 순서 별로 추적 할 수 있다.

- Trace : client가 server로 호출한 큰 트랜잭션 단위
- Span : 각 서비스 별 실행 단위

쉽게 말해 Trace는 전체 트랜잭션의 단위라고 생각하면 될 것이다. 즉, client에서 Request를 보내고 Response를 받을 때 까지 TraceId는 동일하다.

Span Id는 서비스 구간 별 Id라고 생각하는 것이 좋겠다.

각 서비스를 호출 할 때 마다 span Id가 증가하고 이런 span Id의 순서로 서비스 호출 순서를 시간 순으로 알 수 있다.

따라서 각 구간 별 수행 시간을 Span Id로 비교한다면 어느 곳에서 병목현상이 발생 하는지 쉽게 찾을 수 있다.



### Zipkin

MSA환경에서 가장 자주 사용되는 Tracing 도구이다.

Zipkin의 아키텍쳐는 아래와 같다.

![](/Users/carrey/Desktop/git-page/jaehun2841.github.io/img/2018-05-01-msa-basic/zipkin archi.png)



#### 지원하는 프로토콜

Zipkin으로 추적할 수 있는 분산 트랜잭션은 http프로토콜을 기본적으로 지원하고, 자주 사용하는 프로토콜인 gRPC를 함께 지원한다.



#### 클라이언트 라이브러리

![](/Users/carrey/Desktop/git-page/jaehun2841.github.io/img/2018-05-01-msa-basic/클라이언트 라이브러리.png)

zipkin client는 application에서 발생하는 트랜잭션 로그를 수집하여 zipkin collector에 전달하는 역할을 한다.

일반적으로는 http 프로토콜을 이용해 전송한다. 대규모의 서비스의 경우 kafka 큐를 이용해 push하는 방법도 있다고 한다.

지원되는 언어는 활발한 오픈소스 생태계 답게 지원되는 클라이언트 라이브러리가 다양한 언어로 이루어져 있다.



#### 스토리지

각각의 클라이언트에서 zipkin collector에게 트랜잭션 정보를 전달하면, collector는 이를 스토리지에 저장한다.

사용 가능한 스토리지는 

- In-memory : 간단하게 테스트 환경으로 설정해보기 좋다
- My-SQL : 소규모 서비스 환경에서 주로 설정한다.
- Cassandra : 주로 대규모 서비스 운영환경에 걸맞다.
- Elastic Search : 주로 대규모 서비스 운영환경에 걸맞다.



#### 대쉬보드

zipkin client에서 zipkin collector로 트랜잭션 정보가 수집되고,

zipkin collector는 이러한 정보를 스토리지에 저장한다.

zipkin은 스토리지에 저장된 데이터를 시각화하여 보여주는 기능을 제공한다.

![](/Users/carrey/Desktop/git-page/jaehun2841.github.io/img/2018-05-01-msa-basic/zipkin 대쉬보드.png)

Elastic Search기반의 스토리지를 사용하는 경우에는 kibana를 통해 시각화가 가능하다.



### Spring Slueth

위에 Zipkin client중에는 Java를 지원하는 클라이언트 라이브러리도 있다.

Java/Spring 진영에도 대표적인 Zipkin Client 라이브러리가 있는데 그것이 바로 Spring Slueth이다.

Spring에서 지원하는 것이기 때문에 Spring boot 환경에서도 세팅과 사용이 매우 쉽다.

Slueth에서 Zipkin Collector로 정보를 넘기는 원리는 아래와 같다.



![](/Users/carrey/Desktop/git-page/jaehun2841.github.io/img/2018-05-01-msa-basic/spring slueth.png)

MSA환경에서 여러가지 서비스의 호출로 하나의 트랜잭션이 완성될 때, Trace정보가 유지 되어야하는데, 자바 애플리케이션에서는 쓰레드마다 할당되는 쓰레드의 일종의 전역변수인 Thread Local 변수에 이 Trace와 Span Context 정보를 저장하여 유지한다. 



분산 트렌젝션은 HTTP나 gRPC로 들어오기 때문에, Spring Sleuth는 HTTP request가 들어오는 시점과 HTTP request가 다른 서비스로 나가는 부분을 랩핑하여 Trace와 Span Context를 전달한다.

아래 그림과 같이 HTTP로 들어오는 요청의 경우에는 Servlet filter를 이용하여, Trace Id와 Span Id를 받고 (만약에 이 서비스가 맨 처음 호출되는 서비스라서 Trace Id와 Span Id가 없을 경우에는 이를 생성한다.)

, 다른 서비스로 호출을 할 경우에는 RestTemplate 을 랩핑하여, Trace Id와 Span Id와 같은 Context 정보를 실어서 보낸다.



HTTP프로토콜을 이용하여 Trace와 span정보를 보낼때는 Http Header를 이용한다.

![](/Users/carrey/Desktop/git-page/jaehun2841.github.io/img/2018-05-01-msa-basic/slueth http header.png)

실제 x-b3 prefix에 traceId와 spanId를 담아서 다음 서비스로 전송한다.

이렇게 ServletFilter와 RestTemplate을 Spring 프레임웍단에서 랩핑해줌으로써, 개발자는 별도의 트레이스 코드를 넣을 필요 없이 Spring을 이용한다면 분산 트렌젝션을 추적할 수 있도록 해준다. 



### Slueth 설정하기

```xml
		<dependency>
		    <groupId>org.springframework.cloud</groupId>
		    <artifactId>spring-cloud-starter-zipkin</artifactId>
		    <version>1.3.2.RELEASE</version>
		</dependency>
		

		<dependency>
		    <groupId>org.springframework.cloud</groupId>
		    <artifactId>spring-cloud-starter-sleuth</artifactId>
		    <version>1.3.2.RELEASE</version>
		</dependency>
```

Spring boot application에서 zipkin을 이용하기 위해서 위 2개의 dependency를 추가 해준다.



#### 예제 소스

```Java
@RestController
@RequestMapping("/test")
public class TestController {

    @Autowired
    RestTemplate restTemplate;

    @Bean
    public RestTemplate getRestTemplate() {
        return new RestTemplate();
    } 

    @Bean
    public AlwaysSampler alwaysSampler() {
        return new AlwaysSampler();
    }
    
    @RequestMapping
    @ResponseBody
    public Object startTest() {
        return restTemplate.exchange("http://local.service2.com/test2", HttpMethod.GET, null);
	}
}
```



/test로 들어온 요청에서 restTemplate으로 다른 서비스에 요청한 데이터를 return하는 소스 코드이다.

위 소스 코드에서 주의 깊게 봐야 하는 부분은 restTemplate 선언 부분이다.

맨 위에서 @Autowired을 통해 restTemplate을 주입받도록 하였다.

> Import Ant
>
> You have to register RestTemplate as a bean so that the interceptors will be get injected.
>
> If you created a restTemplate instance with a new keyword then the instrument WILL NOT work



인용된 글을 보면 일반적은 new로 RestTemplate을 생성하게 되면 작동하지 않고, bean으로 등록해야지만 interceptor가 

trace와 span 정보를 랩핑할 수 있는듯 하다.



application.yml

```yaml
server:
  port: 8081
spring:
  application:
    name: zipkin-demo-server1
  zipkin:
    baseUrl: http://127.0.0.1:9411/
  sleuth:
    enabled: true
    sampler:
      probability: 1.0 //샘플링 비율 100%
sample:
  zipkin:
    enabled: true
```



Zipkin Server의 Url과 샘플링 비율등을 설정하기 위해서는 src/main/resources/application.yml에 설정 정보를 지정해 놓는다.

위의 sleuth sampling의 비율을 1.0으로 해두었는데 이는 100%를 의미한다.

100%로 하면 전체 트랜잭션 정보를 저장하여 정확한 로그 수집이 되겠지만, 시스템의 부하가 발생할 확률이 높다.

따라서 이 비율을 적당하게 조절하는 것이 좋다.

(트위터의 경우 샘플링 비율을 1/6,000,000으로 설정하여 사용한다고 한다.)



#### Zipkin 서버 구동

https://zipkin.io/pages/quickstart  : zipkin 서버 구동 방법

Docker image를 사용하여 구동하는 방법도 있다



jar파일을 다운 받아 간단하게 구동시키는 방법

```shell
wget -O zipkin.jar 'https://search.maven.org/remote_content?g=io.zipkin.java&a=zipkin-server&v=LATEST&c=exec'
java -jar zipkin.jar
```

이때 주의할점은 zipkin 서버를 통해서 HTTP로 Trace 로그를 받을때, 별도의 보안이나 인증 메커니즘이 없기 때문에, zipkin 서버는 반드시 방화벽 안에 놓고, 서비스 서버로부터만 HTTP 호출을 받을 수 있도록 해야 한다.

 

